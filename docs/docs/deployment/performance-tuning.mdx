---
description: Tune performance of the Hasura GraphQL engine
keywords:
  - hasura
  - docs
  - deployment
sidebar_position: 120
sidebar_label: Performance tuning
---

# Tune Hasura Performance

## Configuration and Deployment

### Tweak Postgres configuration

PostgreSQL's basic configuration is tuned for wide compatibility rather than performance. The default parameters are very undersized for your system. You can read more details about the configuration settings at the PostgreSQL Wiki. There are also config generator tools that can help us.

- [Tuning Your PostgreSQL Server](https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server)
- Config generator: [https://pgtune.leopard.in.ua](https://pgtune.leopard.in.ua)

### Hasura configuration

#### HASURA GRAPHQL PG CONNECTIONS
- Environment variable: `HASURA_GRAPHQL_PG_CONNECTIONS`
- Minimum **2** connections
- Default value: **50**
- Max connections: = Max connections of Postgres - 5 (keep free connections for another services, e.g PGAdmin, metrics tools)

However, how many connections is the best setting? Of course, it depends on the Postgres server's hardware specifications. Moreover, too many connections doesn't mean query performance will be the highest. There are many great articles that analyze this deeper:

- [https://brandur.org/postgres-connections](https://brandur.org/postgres-connections)
- [https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing)

There isn't a silver bullet for all server specs. Your developer has to test and benchmark carefully for the final result. However, at a start point, you can estimate with this formula, then test around this value:

```
connections = ((core_count * 2) + effective_spindle_count)
```

For example, if your server has a 4 Core i7 CPU and 1 hard disk, it should have a connection pool of: 9 = ((4 * 2) + 1). Call it 10, as a nice round number.

For high transaction applications, a horizontal scale with multiple GraphQL Engine clusters is the best practice. However, you should be aware of the total connections of all nodes. The number must be lower than the maximum connections of Postgres

#### HASURA GRAPHQL CONNECTIONS PER READ REPLICA

- Environment variable: `HASURA_GRAPHQL_CONNECTIONS_PER_READ_REPLICA`

With Read-replica, Hasura can load balance multiple databases. However, you will need to balance connections between database nodes too:
- Master connections (`HASURA_GRAPHQL_PG_CONNECTIONS`) are now used for writing only. You can decrease max connections lower if Hasura doesn't write much, or share connections with other Hasura nodes.
- Currently, read-replica connections use one setting for all databases. It can't flexibly configure specific values for each node. Therefore, you need to be aware of the total connections when scaling Hasura to multiple nodes.

#### HASURA GRAPHQL LIVE QUERIES MULTIPLEXED REFETCH INTERVAL

- Environment variable: `HASURA_GRAPHQL_LIVE_QUERIES_MULTIPLEXED_REFETCH_INTERVAL`

*(Can skip it if you don't use subscription)*

Default: 1000 (1 second)

In brief, live query subscribers are grouped with the same query and variables. The GraphQL Engine just needs to execute one query and return the same results to clients once every refetch interval.

The smaller the interval is, the faster the update clients receive. However, everything has a cost. Small intervals with a large number of subscriptions need high CPU and memory resources. If you don't really need too much realtime, the interval can be set a bit longer. In contrast, with a small-medium number of subscriptions, the default value (1 second) is good enough

#### HASURA GRAPHQL LIVE QUERIES MULTIPLEXED BATCH SIZE

- Environment variable: `HASURA_GRAPHQL_LIVE_QUERIES_MULTIPLEXED_BATCH_SIZE`

*(Can skip it if you don't use subscription)*

Default: 100

Imagine there are 1,000,000 subscribers that subscribe to the same query. Emitting to millions of websockets in sequence can cause delays and eat more memory in a long queue. However, a small batch size can increase the number of SQL transactions. This value needs to be kept in balance. If you don't have an idea to determine what value to use, just use the default value

### Scale Hasura

Hasura GraphQL Engine binary is containerized by default, so it is easy to scale horizontally. You need to estimate concurrent requests/second, benchmark how many requests 1 Hasura node can load, then scale multiple nodes with a simple calculation:

```
total_nodes = required_ccu / requests_per_node + backup_node
```

`backup_node` is `0` or `1`, depending on your plan

However, you need to be aware of the total Postgres connections. Default `HASURA_GRAPHQL_PG_CONNECTIONS` value is `50`, meanwhile default Postgres `max_connections` configuration is `100`. The Postgres server will easily be out of connections with `3` Hasura nodes, or `2` nodes with events/action services that connect directly to the database.

```
pg_max_connections >= hasura_nodes * hasura_pg_connections + event_nodes * event_pg_connections
```

### Scale PostgreSQL Servers

Hasura GraphQL Engine is a query engine that utilizes the power of a database, so the performance of Postgres directly affects Hasura's performance. However, it isn't easy to do if you don't have much Database Admin knowledge. Moreover, there are many Postgres extensions and scaling tools, if you don't have an idea what tool to use, and does it work well with Hasura.

I did some experiments to test and compare popular tools [here](https://github.com/hgiasac/hasura-postgres-at-scale), and can give you some opinion tips:

- The easiest way is to use Cloud SQL Services (GCP, AWS, Azure...). Cloud Providers can ensure high availability at an extra cost. [Hasura Pro](https://hasura.io/hasura-pro/) supports load balancing with Read-replica and utilizes master-standby databases' performance easily with one line of config. You can also use [PgBouncer](https://www.pgbouncer.org/) proxy over Postgres databases if require too many connections.
- In contrast, high availability is critical for on-premise servers. However, with the help of Docker Swarm/Kubernetes, deployment work is easier. IMO, you can easily deploy a high availability and load-balancing Hasura stack with `repmgr` and `Hasura Pro`. However, it is safer if you use 1 master + 2 standby clusters.
- If you don't like Hasura Pro, you can use another load balancer such as [PgPool II](https://www.pgpool.net/mediawiki/index.php/Main_Page) or [HAProxy + PGBouncer](https://www.percona.com/blog/2018/10/02/scaling-postgresql-using-connection-poolers-and-load-balancers-for-an-enterprise-grade-environment/) stack. However, it takes extra work to setup and has more server costs. IMO, the extra server cost won't be cheaper than Hasura Pro.

You can read more detail about Postgres at scale [here](https://github.com/hgiasac/hasura-postgres-at-scale)

### Monitoring

Monitor tools help us track and alert error issues, performance, and hardware usage. It is very critical in production. There are many open-source and commercial services. However, sometimes you have to combine many tools because of the architectural complexity.

#### Hasura

Hasura logging is well structured, in JSON format. It is easy to integrate with Log analytics and monitoring services such as [Datadog](https://www.datadoghq.com/), [Google Cloud Logging](https://cloud.google.com/logging), [Amazon CloudWatch Logs](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html) through Docker/Kubernetes logging drivers.

Hasura Pro also provides a Metrics Monitor that analyzes operations, errors, and performance with a friendly interface

![Hasura usage](/img/deployment/hasura-usage.png)

#### Server + Postgres

- If you use cloud services (GCP, AWS, Azure...), they provide built-in metrics of server usage (CPU, RAM, network...).
- On-premise servers, we can use open source docker services such as [cAdvisor](https://github.com/google/cadvisor), or commercial services such as [okMeter](https://okmeter.io/)
- With Postgres, we can use [pgMonitor](https://github.com/CrunchyData/pgmonitor), [pgwatch2](https://github.com/cybertec-postgresql/pgwatch2) or commercial [okMeter](https://okmeter.io/)

## Software Architecture and Best Practices

### Hasura as Data service

#### Connection Pooler

Database connection management isn't an easy task, especially when scaling to multiple application nodes. There are common issues such as connection leaking, and maximum connections exceeded. If you use serverless applications for actions/event triggers that connect directly to a database, connection leaking is unavoidable, because every invocation may result in a new connection to the database, especially when the number of services has grown to hundreds.

We can use many solutions such as PgBouncer, vertical scaling, and increasing `max_connections` on Postgres configurations. However, increasing too many connections can backstab your server, and affect performance.

Therefore, we can reduce connection usage by querying data from the GraphQL Engine instead. Connection polling will be centralized in Hasura nodes.

![hasura connection pooling](/img/deployment/hasura-connection-poller.png)

You can read more in [Hasura Blog](https://hasura.io/blog/level-up-your-serverless-game-with-a-graphql-data-as-a-service-layer/)

#### Load Balancer (Pro)

Read replica on Hasura Pro can load balance master and standby nodes. Therefore, it can be an easy-to-use alternative to PgPool or HAProxy.

![hasura load-balancer](/img/deployment/hasura-load-balancer.png)

### Understand your data

Hasura's query performance relies on Database performance. When there is any performance issue, you need profiling to check the bottleneck point, and optimize your database queries. Utilizing the power of Postgres can help boost application speed.

Fundamental knowledge you should know and practice:
- Index your table
- Optimize queries with view, materialized view, and functions
- Use trigger to update data instead of using 2 or more request calls
- Normalize data structure
- EXPLAIN, ANALYZE

### Query tips

- Avoid too many `_or` conditions. It doesn't utilize table index
- `like`, `ilike` is expensive, especially on long text. Use [Full text search](https://hasura.io/blog/full-text-search-with-hasura-graphql-api-postgres/) instead
- Pagination is necessary.
- Fetching batched multiple queries in one request is useful. However, you shouldn't overuse it. One common case is using aggregate count with data in the same pagination query. It is okay for small to medium tables. However, when the table size is large, the query will be slow because of the entire table query scan
- Avoid joining too many tables.

### Microservices

Hardware has its limits. You have to throw a lot of money to scale servers as well as data optimization. Moreover, Postgres doesn't support master-master replica, so it will be a bottleneck if we store all the data in one database. Therefore, you can divide your business logic into multiple smaller services, or microservices.

Hasura encourages microservices with Remote Schema. It can take responsibility as an API Gateway that routes to multiple smaller GraphQL servers.

![hasura load-balancer](/img/deployment/hasura-microservices.png)

For example, for an e-commerce application, you can design 3 Hasura services:
- User + Authentication
- Product management
- Order + Transactions

The design philosophy is flexible depending, on the project scope. On a small-size project, one database can be good enough. The downside is that remote schemas can't join data with each other. However, it will be gone after [remote-join PR](https://github.com/hasura/graphql-engine/pull/2392) is merged

### Postgres ecosystem

Thanks to the open source community, Postgres has many extensions for various types of applications:
- Time-series data, metrics, IoT: [TimescaleDB](https://www.timescale.com/), [CitusDB](https://www.citusdata.com/)
- Spatial and geographic objects: [PostGIS](https://postgis.net/)
- Image processing: [PostPic](https://github.com/drotiro/postpic)

With remote schema, we can use Hasura with multiple databases for various use cases, for example, Postgres for user data, TimescaleDB for transaction logs, and Postgis for Geographic service.

## Summary

Optimization and scaling are complicated work that require the combination of server architecture and software design. We have to keep monitoring, profiling, and refactoring step by step. Postgres is a single point of failure. GraphQL Engine is on the application level, and it can't automatically the optimize database for us.

Hope this guide can help you using Hasura better at scale.